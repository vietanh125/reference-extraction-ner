{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue May 26 10:56:00 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 430.40       Driver Version: 430.40       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:01:00.0  On |                  N/A |\n",
      "| 30%   61C    P2   210W / 260W |  10968MiB / 11016MiB |     22%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0      1395      G   /usr/lib/xorg/Xorg                           172MiB |\n",
      "|    0      3959      G   compiz                                       188MiB |\n",
      "|    0     13210      G   unity-control-center                           6MiB |\n",
      "|    0     15555      G   ...uest-channel-token=16444902768939799852    39MiB |\n",
      "|    0     21322      G   ...AAAAAAAAAAAACAAAAAAAAAA= --shared-files    78MiB |\n",
      "|    0     29959      C   python                                     10457MiB |\n",
      "+-----------------------------------------------------------------------------+\n",
      "              total        used        free      shared  buff/cache   available\n",
      "Mem:          15970       12045         705         532        3219        2810\n",
      "Swap:           979         968          11\n"
     ]
    }
   ],
   "source": [
    "# %run -i data_process.py\n",
    "!nvidia-smi\n",
    "!free -m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "# from keras_contrib.layers import CRF\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "import pickle\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import Callback, ModelCheckpoint\n",
    "from seqeval.metrics import classification_report, f1_score\n",
    "\n",
    "# from tensorflow.keras.layers import add\n",
    "# from nlp_architect.nn.tensorflow.python.keras.layers.crf import CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_padding(y_test, y_pred, tags2idx):\n",
    "    '''\n",
    "    cắt padding ở cu￿ối m￿ỗi c￿âu trong y_t￿est v￿à y_pred tương ứng\n",
    "\n",
    "    :param y_test: [1, 1, 1, 1, 0, 0, 0, 0]\n",
    "    :param y_pred: [1, 1, 2, 2, 2, 1, 3, 0]\n",
    "    :param tags2idx: {'B-L': 1, 'I-L':2, 'pad':0}\n",
    "\n",
    "    :return:\n",
    "        y_test: [1, 1, 1, 1]\n",
    "        y_pred: [1, 1, 2, 2]\n",
    "    '''\n",
    "    y_pred_trim = []\n",
    "    y_test_trim = []\n",
    "    for i, y in enumerate(y_test):\n",
    "        first_pad_list = np.where(y == tags2idx['pad'])[0]\n",
    "        pred = y_pred[i]\n",
    "        if len(first_pad_list) != 0:\n",
    "            y = y[:first_pad_list[0]]\n",
    "            pred = pred[:first_pad_list[0]]\n",
    "        y_pred_trim.append(pred)\n",
    "        y_test_trim.append(y)\n",
    "    y_test = np.concatenate(y_test_trim).ravel()\n",
    "    y_pred = np.concatenate(y_pred_trim).ravel()\n",
    "    return y_test, y_pred\n",
    "\n",
    "def spit_nested_labels(y):\n",
    "    y_nested = []\n",
    "    for i, row in enumerate(y):\n",
    "        nested = []\n",
    "        for j, x in enumerate(row):\n",
    "            n = x.split('_')\n",
    "            if len(n) > 1:\n",
    "                nested.append(n[1])\n",
    "                y[i][j] = n[0]\n",
    "            else:\n",
    "                nested.append('O')\n",
    "        y_nested.append(nested)\n",
    "    return np.append(y, np.array(y_nested), 1)\n",
    "\n",
    "\n",
    "\n",
    "class F1Callback(Callback):\n",
    "    def __init__(self, X_val, y_val):\n",
    "        super().__init__()\n",
    "        self.X_val = X_val\n",
    "#         self.X_train = X_train\n",
    "#         self.y_train = y_train\n",
    "        self.y_val = y_val\n",
    "        self.maps = []\n",
    "\n",
    "    def eval_map(self, X, y):\n",
    "#         x_val, y_true = X, y\n",
    "        y_pred = self.model.predict(X)\n",
    "        y_pred = np.argmax(y_pred, axis=2)\n",
    "        y = np.argmax(y, axis=2)\n",
    "        y_pred = np.vectorize(idx2tags.get)(y_pred)\n",
    "        y = np.vectorize(idx2tags.get)(y)\n",
    "\n",
    "        y = spit_nested_labels(y)\n",
    "        y_pred = spit_nested_labels(y_pred)\n",
    "        score = f1_score(y.tolist(), y_pred.tolist())\n",
    "        del X, y, y_pred\n",
    "        return score\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        val = self.eval_map(self.X_val, self.y_val)\n",
    "#         train = self.eval_map(self.X_train, y_train)\n",
    "        print(\" - F1_val: %f\"%(val))\n",
    "        self.maps.append(val)\n",
    "\n",
    "def crop(dimension, start, end):\n",
    "    # Crops (or slices) a Tensor on a given dimension from start to end\n",
    "    # example : to crop tensor x[:, :, 5:10]\n",
    "    # call slice(2, 5, 10) as you want to crop on the second dimension\n",
    "    def func(x):\n",
    "        if dimension == 0:\n",
    "            return x[start: end]\n",
    "        if dimension == 1:\n",
    "            return x[:, start: end]\n",
    "        if dimension == 2:\n",
    "            return x[:, :, start: end]\n",
    "        if dimension == 3:\n",
    "            return x[:, :, :, start: end]\n",
    "        if dimension == 4:\n",
    "            return x[:, :, :, :, start: end]\n",
    "    return Lambda(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1303, 128, 1329)\n",
      "(1296, 128, 1329)\n",
      "(1302, 128, 1329)\n",
      "(5237, 128, 1329) (5237, 128)\n",
      "['B-BL' 'B-HP' 'B-L' 'B-ND' 'B-NQ' 'B-PL' 'B-QD' 'B-TT' 'B-TTLT' 'I-BL'\n",
      " 'I-HP' 'I-L' 'I-L_B-BL' 'I-L_B-L' 'I-L_B-ND' 'I-L_I-BL' 'I-L_I-L'\n",
      " 'I-L_I-ND' 'I-ND' 'I-ND_B-L' 'I-ND_B-ND' 'I-ND_B-TT' 'I-ND_I-L'\n",
      " 'I-ND_I-ND' 'I-ND_I-TT' 'I-NQ' 'I-PL' 'I-PL_B-PL' 'I-PL_I-PL' 'I-QD'\n",
      " 'I-TT' 'I-TTLT' 'I-TT_B-ND' 'I-TT_B-TT' 'I-TT_I-ND' 'I-TT_I-TT' 'O' 'pad']\n"
     ]
    }
   ],
   "source": [
    "X = np.load(\"X_1.npy\").astype(np.float32)\n",
    "print(X.shape)\n",
    "\n",
    "X2 = np.load(\"X_2.npy\").astype(np.float32)\n",
    "print(X2.shape)\n",
    "X = np.vstack((X, X2))\n",
    "del X2\n",
    "\n",
    "X3 = np.load(\"X_3.npy\").astype(np.float32)\n",
    "print(X3.shape)\n",
    "X = np.vstack((X, X3))\n",
    "del X3\n",
    "\n",
    "X5 = np.load(\"X_5.npy\").astype(np.float32)\n",
    "X = np.vstack((X, X5))\n",
    "del X5\n",
    "\n",
    "y = np.load(\"y_1.npy\")\n",
    "y2 = np.load(\"y_2.npy\")\n",
    "y3 = np.load(\"y_3.npy\")\n",
    "y5 = np.load(\"y_5.npy\")\n",
    "y = np.vstack((y, y2, y3, y5))\n",
    "del y3, y2, y5\n",
    "print(X.shape, y.shape)\n",
    "print(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 128, 1329)]       0         \n",
      "_________________________________________________________________\n",
      "masking (Masking)            (None, 128, 1329)         0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 128, 400)          1837200   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 128, 400)          722400    \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 128, 37)           14837     \n",
      "=================================================================\n",
      "Total params: 2,574,437\n",
      "Trainable params: 2,574,437\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "66/66 [==============================] - ETA: 0s - loss: 0.3497 - F1_val: 0.486269\n",
      "66/66 [==============================] - 71s 1s/step - loss: 0.3497 - val_loss: 0.1566\n",
      "Epoch 2/50\n",
      " 4/66 [>.............................] - ETA: 43s - loss: 0.1431"
     ]
    }
   ],
   "source": [
    "tags2idx = {'B-HP': 0, 'B-TTLT': 2, 'I-PL_I-PL': 3, 'I-ND_I-TT': 4, 'I-NQ': 5, 'I-L_I-BL': 6, 'I-TTLT': 7, 'B-L': 8, 'I-ND_I-L': 9, \n",
    "            'I-ND_I-ND': 10, 'I-ND_B-TT': 11, 'I-HP': 12, 'I-ND': 13, 'I-TT': 14, 'I-PL': 15, 'I-QD': 16, 'I-L_I-L': 17, 'B-BL': 18, \n",
    "            'I-TT_B-ND': 19, 'I-L_B-ND': 20, 'I-ND_B-L': 21, 'B-ND': 22, 'B-PL': 23, 'I-BL': 24, 'B-QD': 25, 'I-L_I-ND': 26, 'O': 27, \n",
    "            'I-TT_B-TT': 28, 'B-NQ': 29, 'I-L_B-L': 30, 'I-L_B-BL': 31, 'I-TT_I-ND': 32, 'I-TT_I-TT': 33, 'I-L': 34, 'B-TT': 35, \n",
    "            'I-PL_B-PL': 36, 'I-ND_B-ND': 1}\n",
    "y[y=='pad'] = 'O'\n",
    "y = np.vectorize(tags2idx.get)(y)\n",
    "idx2tags = {v: k for k, v in tags2idx.items()}\n",
    "y = np.array([to_categorical(l, num_classes=len(tags2idx.keys())) for l in y])\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
    "del X, y\n",
    "filepath=\"models/branches-{epoch:02d}-{val_loss:.4f}.h5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "# model = load_model(\"models/model.h5\")\n",
    "\n",
    "inp = Input(shape=(128, 1329))\n",
    "x = Masking(mask_value=0., input_shape=(128, 1329))(inp)\n",
    "# bert = crop(2, 0, 1024)(x)\n",
    "# ft = crop(2, 0, 1324)(x)\n",
    "# x = crop(2, 1324, 1329)(x)\n",
    "# bert = Bidirectional(GRU(200, return_sequences=True, dropout=0.5))(bert)\n",
    "# bert = Bidirectional(GRU(200, return_sequences=True, dropout=0.5))(bert)\n",
    "\n",
    "# ft = Bidirectional(GRU(200, return_sequences=True, dropout=0.5))(ft)\n",
    "# ft = Bidirectional(GRU(50, return_sequences=True, dropout=0.2))(ft)\n",
    "\n",
    "x = Bidirectional(GRU(200, return_sequences=True, dropout=0.5))(x)\n",
    "x = Bidirectional(GRU(200, return_sequences=True, dropout=0.5))(x)\n",
    "\n",
    "# x = concatenate([ft, x])\n",
    "# x = TimeDistributed(Dense(64, activation='relu'))(x)\n",
    "output = TimeDistributed(Dense(len(tags2idx.keys()), activation='softmax'))(x)\n",
    "\n",
    "# x = Dense(len(tags2idx.keys()))(x)\n",
    "# sequence_lengths = Input(shape=(1,), dtype=\"int32\", name=\"seq_lens\")\n",
    "# crf = CRF(len(tags2idx.keys()))\n",
    "# output = crf(inputs=x, sequence_lengths=sequence_lengths)\n",
    "\n",
    "model = Model(inp, output)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "model.summary()\n",
    "\n",
    "# train_inputs = [X_train]\n",
    "# val_inputs = [X_val]\n",
    "# print(np.count_nonzero(np.sum(X_train, axis=2), axis=1).reshape(-1, 1)[3])\n",
    "# train_inputs.append(np.count_nonzero(np.sum(X_train, axis=2), axis=1).reshape(-1, 1))\n",
    "# val_inputs.append(np.count_nonzero(np.sum(X_val, axis=2), axis=1).reshape(-1, 1))\n",
    "callback = F1Callback(X_val, y_val)\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=50, batch_size=64, shuffle=True, callbacks=[callback])\n",
    "model.save('models/model.h5')\n",
    "\n",
    "# model = load_model('model.h5', custom_objects={'CRF': CRF}, compile=False)\n",
    "\n",
    "del X_train, y_train, X_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags2idx = {'B-HP': 0, 'B-TTLT': 2, 'I-PL_I-PL': 3, 'I-ND_I-TT': 4, 'I-NQ': 5, 'I-L_I-BL': 6, 'I-TTLT': 7, 'B-L': 8, 'I-ND_I-L': 9, \n",
    "            'I-ND_I-ND': 10, 'I-ND_B-TT': 11, 'I-HP': 12, 'I-ND': 13, 'I-TT': 14, 'I-PL': 15, 'I-QD': 16, 'I-L_I-L': 17, 'B-BL': 18, \n",
    "            'I-TT_B-ND': 19, 'I-L_B-ND': 20, 'I-ND_B-L': 21, 'B-ND': 22, 'B-PL': 23, 'I-BL': 24, 'B-QD': 25, 'I-L_I-ND': 26, 'O': 27, \n",
    "            'I-TT_B-TT': 28, 'B-NQ': 29, 'I-L_B-L': 30, 'I-L_B-BL': 31, 'I-TT_I-ND': 32, 'I-TT_I-TT': 33, 'I-L': 34, 'B-TT': 35, \n",
    "            'I-PL_B-PL': 36, 'I-ND_B-ND': 1}\n",
    "idx2tags = {v: k for k, v in tags2idx.items()}\n",
    "\n",
    "X = np.load(\"X_4.npy\").astype(np.float32)\n",
    "print(X.shape)\n",
    "# X3 = np.load(\"X_5.npy\").astype(np.float32)\n",
    "# print(X3.shape)\n",
    "# X = np.vstack((X, X3))\n",
    "\n",
    "y = np.load(\"y_4.npy\")\n",
    "# y4 = np.load(\"y_5.npy\")\n",
    "# # y5 = np.load(\"y_5.npy\")\n",
    "# y = np.vstack((y, y4))\n",
    "y[y=='pad'] = 'O'\n",
    "def eval(X, y, model):\n",
    "    y_pred = np.argmax(model.predict(X), axis=2)\n",
    "    y_pred = np.vectorize(idx2tags.get)(y_pred)\n",
    "    y_test = spit_nested_labels(y)\n",
    "    y_pred = spit_nested_labels(y_pred)\n",
    "    print(classification_report(y_test.tolist(), y_pred.tolist(), digits=4))\n",
    "    \n",
    "import os\n",
    "path = \"models\"\n",
    "ls = os.listdir(path)\n",
    "ls = ['model-19-0.0183.h5']\n",
    "for name in ls:\n",
    "    if name.split('.')[-1] == 'h5':\n",
    "        model = load_model(path + '/' + name)\n",
    "        print(name)\n",
    "        eval(X, y, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vietanh",
   "language": "python",
   "name": "vietanh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
